{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import corner as corner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from populations.bbh_models import get_models\n",
    "import populations.bbh_models as read_models\n",
    "from populations.utils.flow import NFlow\n",
    "from populations.Flowsclass_dev import FlowModel\n",
    "from populations import gw_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #reading the pop synth file functions\n",
    "def get_model_keys(path):\n",
    "    alpha_val = '10'\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    f.close()\n",
    "\n",
    "    # use only models with given alpha value\n",
    "    for model in all_models:\n",
    "        if 'alpha' in model:\n",
    "            if 'alpha'+alpha_val in model:\n",
    "                models.append('/'+model)\n",
    "        else:\n",
    "            models.append('/' + model)\n",
    "    return(np.split(np.array(models), 5))\n",
    "\n",
    "def get_model_keys_CE(path):\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name ,obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    return(np.split(np.array(models), 4))\n",
    "\n",
    "def read_hdf5(path, all_alpha=False):\n",
    "    if all_alpha:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys_CE(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "    else:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "\n",
    "    return(popsynth_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m observations, obsdata, p_theta, events \u001b[39m=\u001b[39m gw_obs\u001b[39m.\u001b[39mgenerate_observations(params, gw_path, \\\n\u001b[1;32m      5\u001b[0m                                             \u001b[39m10000\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mposteriors\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m popsynth_outputs \u001b[39m=\u001b[39m read_hdf5(file_path, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m flow \u001b[39m=\u001b[39m FlowModel\u001b[39m.\u001b[39;49mfrom_samples([\u001b[39m'\u001b[39;49m\u001b[39mCE\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mSMT\u001b[39;49m\u001b[39m'\u001b[39;49m], popsynth_outputs, params, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m flow\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39m/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/flow_models/\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mCE\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSMT\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/PhD/Project_work/AMAZE_model_selection/populations/Flowsclass_dev.py:113\u001b[0m, in \u001b[0;36mFlowModel.from_samples\u001b[0;34m(channel, samples, params, sensitivity, normalize, detectable, device)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     optimal_snrs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(samples))\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m FlowModel(channel, samples, params, cosmo_weights, sensitivity, pdets, optimal_snrs, alpha,\n\u001b[1;32m    114\u001b[0m                  normalize\u001b[39m=\u001b[39;49mnormalize, detectable\u001b[39m=\u001b[39;49mdetectable, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Documents/PhD/Project_work/AMAZE_model_selection/populations/Flowsclass_dev.py:182\u001b[0m, in \u001b[0;36mFlowModel.__init__\u001b[0;34m(self, label, samples, params, cosmo_weights, sensitivity, pdets, optimal_snrs, alpha, normalize, detectable, device)\u001b[0m\n\u001b[1;32m    179\u001b[0m total_hps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhps[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhps[\u001b[39m1\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[1;32m    181\u001b[0m channel_ids \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mCE\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCHE\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGC\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNSC\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m3\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSMT\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m4\u001b[39m}\n\u001b[0;32m--> 182\u001b[0m channel_id \u001b[39m=\u001b[39m channel_ids[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchannel_label] \u001b[39m#will be 0, 1, 2, 3, or 4\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m#number of data points (total) for each channel\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m#no_binaries is total number of samples across sub-populations for non-CE channels, and no samples in each sub-population for CE channel\u001b[39;00m\n\u001b[1;32m    185\u001b[0m channel_samples \u001b[39m=\u001b[39m [\u001b[39m1e6\u001b[39m,\u001b[39m864124\u001b[39m,\u001b[39m896611\u001b[39m,\u001b[39m582961\u001b[39m, \u001b[39m4e6\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "params = ['mchirp','q', 'chieff', 'z']\n",
    "file_path='/Users/stormcolloms/Documents/PhD/Project_work/OneChannel_Flows/models_reduced.hdf5'\n",
    "gw_path = '/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/gw_events'\n",
    "observations, obsdata, p_theta, events = gw_obs.generate_observations(params, gw_path, \\\n",
    "                                            10000, 'posteriors', None)\n",
    "\n",
    "popsynth_outputs = read_hdf5(file_path, True)\n",
    "flow = FlowModel.from_samples('CE', popsynth_outputs, params, device='cpu')\n",
    "flow.load_model('/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/flow_models/', 'CE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, obsdata, p_theta, events = gw_obs.generate_observations(params, gw_path, \\\n",
    "                                            3, 'test', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(obsdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 10000)\n",
      "[-3.97861105e+00 -6.07484616e+00 -1.02101529e+01 -7.36015786e+00\n",
      " -1.32874797e-01 -6.16581793e+00 -2.62227205e+01 -1.48091157e-02\n",
      " -8.26205653e-02  1.00617512e+00 -2.48290837e+00 -2.62279036e+00\n",
      " -5.56160987e+00 -9.04078439e+00 -6.42973298e+00 -3.25261766e+01\n",
      " -7.29458759e+00 -4.28282795e+00 -9.65654473e+00 -2.88546126e+01\n",
      " -2.68162858e+01 -2.25253293e+01 -6.20223731e+00 -1.49162990e+01\n",
      " -3.00532040e+00 -6.81211561e+00 -1.46061702e+00 -7.26339036e-01\n",
      " -1.22298123e+00 -1.73047525e+00 -8.23899096e+00 -3.88733039e+00\n",
      " -7.31338903e+00 -2.53008956e+01 -2.42271698e+01 -6.96990828e+00\n",
      " -7.04269063e+00 -1.98085152e-01 -1.65881190e+01  0.00000000e+00\n",
      "  4.55217520e-01 -4.31250048e+00 -5.12776458e+00 -1.25487474e+01\n",
      " -2.52573052e+01 -2.59583538e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.97861105e+00, -6.07484616e+00, -1.02101529e+01, -7.36015786e+00,\n",
       "       -1.32874797e-01, -6.16581793e+00, -2.62227205e+01, -1.48091157e-02,\n",
       "       -8.26205653e-02,  1.00617512e+00, -2.48290837e+00, -2.62279036e+00,\n",
       "       -5.56160987e+00, -9.04078439e+00, -6.42973298e+00, -3.25261766e+01,\n",
       "       -7.29458759e+00, -4.28282795e+00, -9.65654473e+00, -2.88546126e+01,\n",
       "       -2.68162858e+01, -2.25253293e+01, -6.20223731e+00, -1.49162990e+01,\n",
       "       -3.00532040e+00, -6.81211561e+00, -1.46061702e+00, -7.26339036e-01,\n",
       "       -1.22298123e+00, -1.73047525e+00, -8.23899096e+00, -3.88733039e+00,\n",
       "       -7.31338903e+00, -2.53008956e+01, -2.42271698e+01, -6.96990828e+00,\n",
       "       -7.04269063e+00, -1.98085152e-01, -1.65881190e+01,  0.00000000e+00,\n",
       "        4.55217520e-01, -4.31250048e+00, -5.12776458e+00, -1.25487474e+01,\n",
       "       -2.52573052e+01, -2.59583538e+01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llks = flow(obsdata,[3,1])\n",
    "llks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.87116108e-02, 2.30000000e-03, 3.67948417e-05, 6.36098040e-04,\n",
       "       8.75574710e-01, 2.10000000e-03, 4.08900060e-12, 9.85300000e-01,\n",
       "       9.20700427e-01, 2.73511949e+00, 8.35000234e-02, 7.26000000e-02,\n",
       "       3.84258537e-03, 1.18477867e-04, 1.61288145e-03, 7.48274598e-15,\n",
       "       6.79204981e-04, 1.38035711e-02, 6.40052958e-05, 2.94171752e-13,\n",
       "       2.25857789e-12, 1.64958154e-10, 2.02489525e-03, 3.32608741e-07,\n",
       "       4.95228846e-02, 1.10036250e-03, 2.32093025e-01, 4.83676475e-01,\n",
       "       2.94351330e-01, 1.77200176e-01, 2.64150654e-04, 2.05000000e-02,\n",
       "       6.66554246e-04, 1.02792313e-11, 3.00797251e-11, 9.39739091e-04,\n",
       "       8.73772395e-04, 8.20300000e-01, 6.24987696e-08, 1.00000000e+00,\n",
       "       1.57651627e+00, 1.34000013e-02, 5.92980129e-03, 3.54934510e-06,\n",
       "       1.07372165e-11, 5.32635585e-12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(llks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('amaze')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f4eedd3c2b0a4cf443053300595e4c410b663f293e84798d1742802fb2c7c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
